{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94571a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_ascii(s: str) -> str:\n",
    "    # Remove any non-ASCII characters from the string\n",
    "    return ''.join(c for c in s if ord(c) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97bdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = os.environ[\"GROQ_API_KEY\"]\n",
    "api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "# api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "# api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# model = \"llama3-70b-8192\"\n",
    "model = \"gemini-2.0-flash\"\n",
    "# model = \"codestral-latest\"\n",
    "# model = \"gpt-4.1-nano\"\n",
    "\n",
    "sanitized_api_key = sanitize_ascii(api_key)\n",
    "# llm = ChatGroq(api_key=sanitized_api_key,model=model)\n",
    "llm = ChatGoogleGenerativeAI(api_key=api_key,model=model)\n",
    "# llm = ChatMistralAI(api_key=api_key,model=model)\n",
    "# llm = ChatOpenAI(api_key=api_key,model=model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm.invoke(\"Hello\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Optional, List, Dict\n",
    "\n",
    "class TerraformFile(BaseModel):\n",
    "    path: str\n",
    "    content: str\n",
    "    \n",
    "class TerraformComponent(BaseModel):\n",
    "    \n",
    "    \"\"\"Represents a component in Terraform.\n",
    "    \n",
    "    Attributes:\n",
    "        name: The name of the component.\n",
    "        main_tf: The main.tf file content.\n",
    "        output_tf: The output.tf file content.\n",
    "        variables_tf: The variables.tf file content.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    name: str = Field(..., description=\"The name of the component.\")\n",
    "    main_tf: str = Field(..., description=\"The main.tf file content.\")\n",
    "    output_tf: str = Field(..., description=\"The output.tf file content.\")\n",
    "    variables_tf: str = Field(..., description=\"The variables.tf file content.\")\n",
    "    \n",
    "class EnvironmentList(BaseModel):\n",
    "    environments: List[TerraformComponent] = Field(default_factory=list)\n",
    "\n",
    "class ModuleList(BaseModel):\n",
    "    modules: List[TerraformComponent] = Field(default_factory=list)\n",
    "\n",
    "class TerraformState(BaseModel):\n",
    "    \"\"\"State for our Terraform code generation agent.\"\"\"\n",
    "    modules: ModuleList = Field(default_factory=ModuleList)\n",
    "    environments: EnvironmentList = Field(default_factory=EnvironmentList)\n",
    "    user_requirements: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template\n",
    "terraform_template = \"\"\"\n",
    "SYSTEM:\n",
    "You are Terraform expert, an AI agent that generates Terraform code for AWS Cloud infrastructure based on the user's requirements:\n",
    "\n",
    "Make sure to separte the environments in below formats for dev, stage and prod:\n",
    "---\n",
    "**Expected Output Format (for each environment):**\n",
    "\n",
    "name: [Name of the environment, either \"dev\", \"stage\", or \"prod\"],\n",
    "main.tf: [Main Terraform code for the environment],\n",
    "output.tf: [Output Terraform code for the environment],\n",
    "variables.tf: [Variables Terraform code for the environment]\n",
    "\n",
    "\n",
    "Make sure to separte the modules in below formats:\n",
    "---\n",
    "**Expected Output Format (for each module):**\n",
    "\n",
    "name: [Name of the module like vpc, security-group, etc],\n",
    "main.tf: [Main Terraform code for the module],\n",
    "output.tf: [Output Terraform code for the module],\n",
    "variables.tf: [Variables Terraform code for the module]\n",
    "\n",
    "Constraints:\n",
    "1. Output must be valid and complete.\n",
    "2. Provide actual code only.\n",
    "3. Do not include any extra commentary or markdown formatting.\n",
    "\n",
    "User requirements: {requirements}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99670038",
   "metadata": {},
   "outputs": [],
   "source": [
    "terraform_template1 = \"\"\"\n",
    "SYSTEM:\n",
    "You are Terraform expert, an AI agent that generates Terraform code for AWS Cloud infrastructure. Based on the user's requirements provided below, generate a JSON object that matches the following schema exactly. Do not include any extra text, markdown formatting, or function call wrappers. The JSON object must have exactly these keys:\n",
    "\n",
    "{{\n",
    "  \"environments\": [\n",
    "      {{\n",
    "          \"name\": string,           // Must be either \"dev\", \"stage\", or \"prod\"\n",
    "          \"main.tf\": string,        // Terraform code for main.tf\n",
    "          \"output.tf\": string,      // Terraform code for output.tf\n",
    "          \"variables.tf\": string    // Terraform code for variables.tf\n",
    "      }}\n",
    "  ],\n",
    "  \"modules\": [\n",
    "      {{\n",
    "          \"name\": string,           // Example: \"vpc\", \"security-group\", etc.\n",
    "          \"main.tf\": string,        // Terraform code for main.tf\n",
    "          \"output.tf\": string,      // Terraform code for output.tf\n",
    "          \"variables.tf\": string    // Terraform code for variables.tf\n",
    "      }}\n",
    "  ],\n",
    "  \"user_requirements\": string    // This should echo the input user requirements\n",
    "}}\n",
    "\n",
    "Constraints:\n",
    "1. Output must be valid JSON that follows the schema above.\n",
    "2. Provide actual Terraform code only.\n",
    "3. Do not include any extra commentary or markdown formatting.\n",
    "\n",
    "User requirements: {requirements}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24489b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_request(state: TerraformState):\n",
    "    \"\"\"Process the user's request and update the state.\"\"\"\n",
    "    return state\n",
    "\n",
    "def generate_terraform_code(state: TerraformState):\n",
    "    \"\"\"Generate Terraform code based on requirements in state.\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate.from_template(terraform_template)\n",
    "    llm_with_structured_output = llm.with_structured_output(TerraformState)\n",
    "    \n",
    "    chain = prompt | llm_with_structured_output\n",
    "    response = chain.invoke({\"requirements\": state.user_requirements})\n",
    "\n",
    "    state.environments = response.environments\n",
    "    state.modules = response.modules\n",
    "    return state\n",
    "\n",
    "# Define the graph\n",
    "graph = StateGraph(TerraformState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"process_request\", process_request)\n",
    "graph.add_node(\"generate_terraform_code\", generate_terraform_code)\n",
    "\n",
    "\n",
    "# Add edges\n",
    "graph.add_edge(START, \"process_request\")\n",
    "graph.add_edge(\"process_request\", \"generate_terraform_code\")\n",
    "graph.add_edge(\"generate_terraform_code\", END)\n",
    "\n",
    "# Compile the graph\n",
    "terraform_app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = terraform_app.invoke({\n",
    "    \"user_requirements\": \"Create a VPC with public and private subnets in AWS with appropriate security groups\"\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Save the files to disk\n",
    "# save_terraform_files(result, \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f79c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "img_data = terraform_app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API\n",
    "            )\n",
    "\n",
    "# Save the image to a file\n",
    "graph_path = \"workflow_graph.png\"\n",
    "with open(graph_path, \"wb\") as f:\n",
    "    f.write(img_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545644a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
